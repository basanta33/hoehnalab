---
layout: chapter
title: Bayesian inference using Markov chain Monte Carlo (MCMC) sampling
output:
  html_document:
    toc: true
    toc_float: true
pdf: true
---
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Bayesian inference using Markov chain Monte Carlo (MCMC) sampling</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style>
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Bayesian inference using Markov chain Monte Carlo (MCMC) sampling</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#chapter-7-bayesian-inference-using-markov-chain-monte-carlo-mcmc-sampling">Chapter 7: Bayesian inference using Markov chain Monte Carlo (MCMC) sampling</a><ul>
<li><a href="#section-some-theory">Section: Some theory</a></li>
<li><a href="#section-markov-chain-monte-carlo-mcmc">Section: Markov chain Monte Carlo (MCMC)</a></li>
<li><a href="#section-7.3-implementing-the-markov-chain-monte-carlo-algorithm">Section 7.3: Implementing the Markov chain Monte Carlo algorithm</a><ul>
<li><a href="#subsection-7.3.1-defining-the-model-class">Subsection 7.3.1: Defining the Model class</a></li>
<li><a href="#subsection-7.3.2-implementing-the-model-class">Subsection 7.3.2: Implementing the Model class</a></li>
<li><a href="#subsection-7.3.3-defining-the-mcmc-class">Subsection 7.3.3: Defining the MCMC class</a></li>
<li><a href="#subsection-7.3.4-implementing-the-mcmc-class">Subsection 7.3.4: Implementing the MCMC class</a></li>
</ul></li>
<li><a href="#section-7.4-exercises">Section 7.4: Exercises</a></li>
</ul></li>
</ul>
</nav>
<div>
<p><a href="{{site.baseurl}}/pdf/chapter7.pdf">pdf version</a></p>
</div>
<h1 id="chapter-7-bayesian-inference-using-markov-chain-monte-carlo-mcmc-sampling">Chapter 7: Bayesian inference using Markov chain Monte Carlo (MCMC) sampling</h1>
<h2 id="section-some-theory">Section: Some theory</h2>
<p>Markov chain Monte Carlo (MCMC) is a numerical method for approximating high-dimensional integrals and/or summations. The method was first described by <span class="citation" data-cites="Metropolis1953">(<span class="citeproc-not-found" data-reference-id="Metropolis1953"><strong>???</strong></span>)</span> and later modified by <span class="citation" data-cites="Hastings1970">(<span class="citeproc-not-found" data-reference-id="Hastings1970"><strong>???</strong></span>)</span>. The algorithm that we will implement in this chapter is often referred to as the Metropolis-Hastings algorithm.</p>
<p>Use of the Metropolis-Hastings algorithm was mostly restricted to the field of statistical physics until it was discovered by statisticians in the mid 1980s <span class="citation" data-cites="Geman1984">(<span class="citeproc-not-found" data-reference-id="Geman1984"><strong>???</strong></span>)</span>. Statisticians, as a group, were largely unaware of the numerical method until <span class="citation" data-cites="Gelfand1990">(<span class="citeproc-not-found" data-reference-id="Gelfand1990"><strong>???</strong></span>)</span> provided a description of the method as a way to approximate intractable probability densities. It is fair to say that MCMC has transformed the field of statistics, and in particular, Bayesian statistics.</p>
<p>Bayesian statisticians are interested in the posterior probability distribution of a parameter, <span class="math inline">\(\theta\)</span>, which can be calculated using Bayes’s theorem as <span class="math display">\[
\Pr(\theta | D) = {\Pr(D | \theta) \, \Pr(\theta) \over \Pr(D)}
\]</span> Here, <span class="math inline">\(\Pr(\theta | D)\)</span> is the posterior probability distribution of the parameter. The posterior probability is a conditional probability: the probability of the parameter conditioned on the observations, <span class="math inline">\(D\)</span>. The other factors in the equation include the likelihood [<span class="math inline">\(\Pr(D | \theta)\)</span>], prior probability distribution of the parameter [<span class="math inline">\(\Pr(\theta)\)</span>], and marginal likelihood [<span class="math inline">\(\Pr(D)\)</span>].</p>
<p>How does Bayesian analysis work in practice? Consider an experiment in which a coin is repeatedly tossed with the objective to estimate the probability that heads appears on a single toss of the coin, a parameter we call <span class="math inline">\(\theta\)</span>. We observe <span class="math inline">\(x\)</span> heads on <span class="math inline">\(n\)</span> tosses of the coin. In a Bayesian analysis, the objective is to calculate the posterior probability of the parameter, which for coin tossing is <span class="math display">\[
f(\theta | x) = {f(x | \theta) f(\theta) \over \int_{0}^{1} f(x | \theta)  f(\theta) \, d\theta}
\]</span> The likelihood, <span class="math inline">\(f(x | \theta)\)</span>, is given by the binomial probability distribution, <span class="math display">\[
f(x | \theta) = {n \choose x} \theta^x (1-\theta)^{n-x}
\]</span> where the binomial coefficient is <span class="math inline">\({n \choose x} = {n! \over x! (n-x)!}\)</span>. In addition to the likelihood function, however, we must also specify a prior probability distribution for the parameter, <span class="math inline">\(f(\theta)\)</span>. This prior distribution should describe the investigator’s beliefs about the hypothesis before the experiment was performed. The problem, of course, is that different people may have different prior beliefs. In this case, it makes sense to use a prior distribution that is flexible, allowing different people to specify different prior probability distributions and also allowing for an easy investigation of the sensitivity of the results to the prior assumptions. A Beta distribution is often used as a prior probability distribution for the binomial parameter. The Beta distribution has two parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Depending upon the specific values chosen for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, one can generate a large number of different prior probability distributions for the parameter <span class="math inline">\(\theta\)</span>. Figure  shows several possible prior distributions for coin tossing. Figure a shows a uniform prior distribution for the probability of heads appearing on a single toss of a coin. In effect, a person who adopts this prior distribution is claiming total ignorance of the dynamics of coin tossing. Figure b shows a prior distribution for a person who has some experience tossing coins; anyone who has tossed a coin realizes that it is impossible to predict which side will face up when tossed, but that heads appears about as frequently as tails, suggesting more prior weight on values around <span class="math inline">\(\theta = 0.5\)</span> than on values near <span class="math inline">\(\theta = 0\)</span> or <span class="math inline">\(\theta = 1\)</span>. Lastly, Figure c shows a prior distribution for a person who suspects he is being tricked. Perhaps the coin that is being tossed is from a friend with a long history of practical jokes, or perhaps this friend has tricked the investigator with a two-headed coin in the past. Figure c, then, might represent the ‘trick-coin’ prior distribution.</p>
<figure>
<img src="{{site.baseurl}}/images/betaPriors.png" alt="" /><figcaption>Figure 7.1. The Beta distribution can take a variety of shapes depending on the values of the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Here, (a) <span class="math inline">\(\alpha = \beta = 1\)</span>, (b) <span class="math inline">\(\alpha = \beta = 4\)</span>, and (c) <span class="math inline">\(\alpha = \beta = 1/2\)</span></figcaption>
</figure>
<p>Besides being flexible, the Beta prior probability distribution has one other admirable property: when combined with a binomial likelihood, the posterior distribution also has a Beta probability distribution (but with the parameters changed). Prior distributions that have this property — that is, the posterior probability distribution has the same functional form as the prior distribution — are called conjugate priors in the Bayesian literature. The Bayesian treatment of the coin tossing experiment can be summarized as follows:</p>
<table>
<colgroup>
<col style="width: 26%" />
<col style="width: 37%" />
<col style="width: 35%" />
</colgroup>
<thead>
<tr class="header">
<th>Prior [<span class="math inline">\(f(\theta)\)</span>, Beta]</th>
<th>Likelihood [<span class="math inline">\(f(x | \theta)\)</span>, Binomial]</th>
<th>Posterior [<span class="math inline">\(f(\theta | x)\)</span>, Beta]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\({\Gamma(\alpha+\beta) \over \Gamma(\alpha) \Gamma(\beta)} \theta^{\alpha-1} (1-\theta)^{\beta-1}\)</span></td>
<td><span class="math inline">\({n \choose x} \theta^x (1-\theta)^{n-x}\)</span></td>
<td><span class="math inline">\({\Gamma(\alpha+\beta + n) \over \Gamma(\alpha + x) \Gamma(\beta + n - x)} \theta^{\alpha + x - 1} (1-\theta)^{\beta + n - x - 1}\)</span></td>
</tr>
</tbody>
</table>
<p>[The gamma function, not to be confused with the gamma probability distribution, is defined as <span class="math inline">\(\Gamma(y) = \int_{0}^{\infty} u^{y-1} e^{-u} \, du\)</span>. <span class="math inline">\(\Gamma(n) = (n - 1)!\)</span> for integer <span class="math inline">\(n = 1, 2, 3, \ldots\)</span> and <span class="math inline">\(\Gamma({1 \over 2}) = \pi\)</span>.] We started with a Beta prior distribution with parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. We used a binomial likelihood, and after some use of our undergraduate calculus we calculated the posterior probability distribution, which is also a Beta distribution but with parameters <span class="math inline">\(\alpha + x\)</span> and <span class="math inline">\(\beta+n-x\)</span>.</p>
<figure>
<img src="{{site.baseurl}}/images/coinPriorPost.png" alt="" /><figcaption>Figure 7.2. As more data are collected for the coin-tossing example, the investigator’s prior opinions play a smaller role in the conclusions. (a) The prior distribution, likelihood function, and posterior probability density when <span class="math inline">\(\alpha = \beta = 4\)</span>, <span class="math inline">\(n = 10\)</span> and <span class="math inline">\(x = 8\)</span>. (b) The prior distribution, likelihood function, and posterior probability density when <span class="math inline">\(\alpha = \beta = 4\)</span>, <span class="math inline">\(n = 100\)</span> and <span class="math inline">\(x = 80\)</span></figcaption>
</figure>
<p>Figure 7.2 shows the relationship between the prior probability distribution, likelihood, and posterior probability distribution of <span class="math inline">\(\theta\)</span> for two different cases, differing only in the number of coin tosses. The posterior probability of a parameter is a compromise between the prior probability and the likelihood. When the number of observations is small, as is the case for Figure 7.2a, the posterior probability distribution is similar to the prior distribution. However, when the number of observations is large, as is the case for Figure 7.2b, the posterior probability distribution is dominated by the likelihood.</p>
<p>Above, we casually claimed that the posterior distribution was a Beta distribution. Working out the math for this problem is informative. The posterior probability distribution for the coin tossing problem can be calculated analytically. Here, we assume a binomial probability distribution for the likelihood, and a Beta prior distribution on <span class="math inline">\(\theta\)</span>, which means the posterior probability distribution of the parameter <span class="math inline">\(\theta\)</span> is: <span class="math display">\[
f(\theta | x) = \frac{ {n \choose x} \theta^x (1-\theta)^{n-x} \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \theta^{\alpha-1} (1-\theta)^{\beta-1} }{ \int_{0}^{1} {n \choose x}  \theta^x (1-\theta)^{n-x} \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \theta^{\alpha-1} (1-\theta)^{\beta-1} d\theta }
\]</span> Note that the denominator involves integration over all possible values of the parameter <span class="math inline">\(\theta\)</span>. Specifically, the probability of heads on a single toss of a coin, <span class="math inline">\(\theta\)</span>, can take values between 0 and 1.</p>
<p>Evaluating the integral in the denominator depends upon the following observation: The Beta probability distribution, like all continuous probability distributions, evaluates to one when integrated over all possible values for the parameter: <span class="math display">\[\begin{eqnarray*}
\int_{0}^{1} \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1} (1-x)^{\beta-1}dx  &amp; = &amp; 1 \\
{\Gamma(\alpha+\beta)  \over \Gamma(\alpha)\Gamma(\beta)} \int_{0}^{1}  x^{\alpha-1} (1-x)^{\beta-1} dx &amp; = &amp; 1 \\
\int_{0}^{1} x^{\alpha-1} (1-x)^{\beta-1} dx  &amp; = &amp; {\Gamma(\alpha)\Gamma(\beta) \over \Gamma(\alpha+\beta) }
\end{eqnarray*}\]</span> The denominator in the equation for the posterior probability distribution of <span class="math inline">\(\theta\)</span>, above, is <span class="math display">\[\begin{eqnarray*}
\int_{0}^{1} {n \choose x} \theta^x (1-\theta)^{n-x}  {\Gamma(\alpha+\beta)  \over \Gamma(\alpha)\Gamma(\beta)} \theta^{\alpha-1} (1-\theta)^{\beta-1} d\theta \\
\frac{ {n \choose x} \Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta) } \int_{0}^{1} \theta^x (1-\theta)^{n-x}   \theta^{\alpha-1} (1-\theta)^{\beta-1} d\theta \\
\frac{ {n \choose x} \Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta) } \int_{0}^{1} \theta^{\alpha+x-1} (1-\theta)^{\beta+n-x-1}   d\theta
\end{eqnarray*}\]</span> Because $<em>{0}^{1} x^{-1} (1-x)^{-1} dx = ()() / (+) $, this means that $</em>{0}^{1} x^{+x-1} (1-x)^{+n-x-1} dx = (+x)(+n-x) /(++ n) $. The posterior probability distribution for <span class="math inline">\(\theta\)</span>, then, is <span class="math display">\[\begin{eqnarray*}
f(\theta | x) &amp; = &amp; \frac{ {n \choose x} \theta^x (1-\theta)^{n-x}  {\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \theta^{\alpha-1} (1-\theta)^{\beta-1} \over
\frac{ {n \choose x} \Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta) } { \Gamma(\alpha+x)\Gamma(\beta+n-x) \over \Gamma(\alpha+\beta + n) } }\\
 &amp; = &amp; {\Gamma(\alpha+\beta+n)  \theta^x (1-\theta)^{n-x}  \theta^{\alpha-1} (1-\theta)^{\beta-1} \over \Gamma(\alpha+x)\Gamma(\beta+n-x)}\\
 &amp; = &amp; { \Gamma(\alpha+\beta+n) \theta^{\alpha+x-1} (1-\theta)^{\beta+n-x-1} \over \Gamma(\alpha+x)\Gamma(\beta+n-x)}
\end{eqnarray*}\]</span> which is a Beta probability distribution with parameters <span class="math inline">\(\alpha+x\)</span> and <span class="math inline">\(\beta+n-x\)</span>.</p>
<p>I will make one comment about the analytical solution of the posterior probability distribution for the coin-tossing problem: <strong>it involved hard math!</strong> Certainly, working through the math was at the edge of my ability. However, for problems that are only slightly more complicated than coin tossing (i.e., almost all other statistical problems), it is not possible to obtain the posterior probability distribution analytically. Until the advent of computers and algorithms for approximating high-dimensional integrals/summation, people were up a river without a paddle if their problem was somewhat complicated (i.e., problems that are actually interesting).</p>
<h2 id="section-markov-chain-monte-carlo-mcmc">Section: Markov chain Monte Carlo (MCMC)</h2>
<p>Even though we know the posterior probability distribution for the coin-tossing problem, we will act as if we don’t and approximate the posterior probability distribution using MCMC. The goal of MCMC is to construct a Markov chain that has as its state space the parameters of the model and a stationary distribution that is the posterior probability of the parameters. How do we construct a Markov chain that has these properties? The answer: Use the Metropolis-Hastings algorithm. The steps of the Metropolis-Hastings algorithm are as follows:</p>
<ol type="1">
<li>Call the current state of the Markov chain <span class="math inline">\(\theta\)</span>. If this is the first cycle of the chain, then initialize <span class="math inline">\(\theta\)</span> to some value. (Perhaps initialize <span class="math inline">\(\theta\)</span> by choosing a value from the prior distribution.)</li>
<li>Propose a new value for <span class="math inline">\(\theta\)</span>, called <span class="math inline">\(\theta&#39;\)</span>. The details of the proposal mechanism are at the discretion of the programmer. However, he/she must follow some rules. For one, the proposal mechanism that is coded must involve random numbers. That is, the proposal mechanism cannot be a deterministic one. Some other requirements are that every state must be potentially reachable given enough applications of the proposal mechanism and the proposal mechanism cannot result in a periodic chain. (The last requirement is generally not an issue.) Finally, you should be able to calculate the probability of proposing the proposed state, <span class="math inline">\(q(\theta \rightarrow \theta&#39;)\)</span> as well as the imagined reverse move, which is not actually made in computer memory, <span class="math inline">\(q(\theta&#39; \rightarrow \theta)\)</span>.</li>
<li>Calculate the probability of accepting the proposed state as the next state of the Markov chain. This probability is the ratio of the posterior probabilities of the proposed and current states times the Hastings ratio: <span class="math display">\[
R = \min \left(1, {f(\theta&#39; | X) \over f(\theta | X)} \times \underbrace{q(\theta&#39; \rightarrow \theta) \over q(\theta \rightarrow \theta&#39;)}_{\mbox{Hastings Ratio}}  \right)
\]</span> It does not appear that we can solve this. After all, the entire point of MCMC is to approximate probability distributions that we cannot solve analytically. Here, things seem especially intractable, because we need to calculate the ratio of two probability distributions that we cannot calculate analytically! Relax. Let’s rewrite the ratio of the posterior probabilities using Bayes’s theorem: <span class="math display">\[
R = \min \left(1, {f(X | \theta&#39;) f(\theta&#39;)/ f(X) \over f(X | \theta) f(\theta)/f(X)} \times {q(\theta&#39; \rightarrow \theta) \over q(\theta \rightarrow \theta&#39;)}  \right)
\]</span> Note that the marginal likelihood, <span class="math inline">\(f(X)\)</span>, cancels. Importantly, it was the marginal likelihood that we cannot calculate analytically. The portions that are left over, after cancelling <span class="math inline">\(f(X)\)</span>, are readily calculable. In the end, our acceptance probability is: <span class="math display">\[
R = \min \left(1, \underbrace{f(X | \theta&#39;) \over f(X | \theta)}_{\mbox{Likelihood Ratio}} \times \underbrace{f(\theta&#39;) \over f(\theta)}_{\mbox{Prior Ratio}} \times \underbrace{q(\theta&#39; \rightarrow \theta) \over q(\theta \rightarrow \theta&#39;)}_{\mbox{Hastings Ratio}}  \right)
\]</span></li>
<li>Generate a uniform(0,1) random variable called <span class="math inline">\(u\)</span>. If <span class="math inline">\(u &lt; R\)</span>, then accept the proposed state as the next state of the Markov chain, setting <span class="math inline">\(\theta = \theta&#39;\)</span>. Otherwise, the chain remains in its current state.</li>
<li>Go to Step # 2.</li>
</ol>
<p>The steps of the Metropolis-Hastings algorithm are repeated many thousands, or millions, of times. The states that are visited form a Markov chain. The key to MCMC is that the sampled states are valid, albeit dependent, draws from the posterior probability distribution.</p>
<h2 id="section-7.3-implementing-the-markov-chain-monte-carlo-algorithm">Section 7.3: Implementing the Markov chain Monte Carlo algorithm</h2>
<h3 id="subsection-7.3.1-defining-the-model-class">Subsection 7.3.1: Defining the Model class</h3>
<p>Create a new file called <strong>Model.h</strong> Work through the code below which needs to be added to the to file.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1"></a><span class="pp">#ifndef Model_h</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="pp">#define Model_h</span></span>
<span id="cb1-3"><a href="#cb1-3"></a></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="pp">#include </span><span class="im">&lt;vector&gt;</span></span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co">// forward declarations</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="kw">class</span> Alignment;</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="kw">class</span> ExponentialDistribution;</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="kw">class</span> PhyloCTMC;</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="kw">class</span> PureBirthProcess;</span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="kw">class</span> RateMatrix_JC;</span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="kw">class</span> Tree;</span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="kw">class</span> UniformDistribution;</span>
<span id="cb1-15"><a href="#cb1-15"></a></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="co">/**</span></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="co"> * </span><span class="an">\class</span><span class="co"> </span><span class="cv">Model</span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="co"> *</span></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="co"> * </span><span class="an">\brief</span><span class="co"> This class represents the phylogenetic model.</span></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="co"> *</span></span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="co"> *</span></span>
<span id="cb1-22"><a href="#cb1-22"></a><span class="co"> *</span></span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="co"> * </span><span class="an">\author</span><span class="co"> Sebastian Höhna</span></span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="co"> *</span></span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="co"> */</span></span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="kw">class</span> Model {</span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-28"><a href="#cb1-28"></a><span class="kw">public</span>:</span>
<span id="cb1-29"><a href="#cb1-29"></a></span>
<span id="cb1-30"><a href="#cb1-30"></a>    Model(<span class="at">const</span> <span class="bu">std::</span>string &amp;fn);</span>
<span id="cb1-31"><a href="#cb1-31"></a>    <span class="kw">virtual</span>                                        ~Model();</span>
<span id="cb1-32"><a href="#cb1-32"></a></span>
<span id="cb1-33"><a href="#cb1-33"></a>    <span class="co">// parameters</span></span>
<span id="cb1-34"><a href="#cb1-34"></a>    <span class="dt">double</span>                                          getBirthRate(<span class="dt">void</span>) <span class="at">const</span>;</span>
<span id="cb1-35"><a href="#cb1-35"></a>    <span class="dt">double</span>                                          getClockRate(<span class="dt">void</span>) <span class="at">const</span>;</span>
<span id="cb1-36"><a href="#cb1-36"></a></span>
<span id="cb1-37"><a href="#cb1-37"></a>    <span class="dt">void</span>                                            setBirthRate( <span class="dt">double</span> r );</span>
<span id="cb1-38"><a href="#cb1-38"></a>    <span class="dt">void</span>                                            setClockRate( <span class="dt">double</span> r );</span>
<span id="cb1-39"><a href="#cb1-39"></a></span>
<span id="cb1-40"><a href="#cb1-40"></a>    <span class="co">// distributions</span></span>
<span id="cb1-41"><a href="#cb1-41"></a>    <span class="dt">double</span>                                          getBirthRatePrior(<span class="dt">void</span>);</span>
<span id="cb1-42"><a href="#cb1-42"></a>    <span class="dt">double</span>                                          getClockRatePrior(<span class="dt">void</span>);</span>
<span id="cb1-43"><a href="#cb1-43"></a>    <span class="dt">double</span>                                          getLikelihood(<span class="dt">void</span>);</span>
<span id="cb1-44"><a href="#cb1-44"></a>    <span class="dt">double</span>                                          getTreePrior(<span class="dt">void</span>);</span>
<span id="cb1-45"><a href="#cb1-45"></a></span>
<span id="cb1-46"><a href="#cb1-46"></a><span class="kw">private</span>:</span>
<span id="cb1-47"><a href="#cb1-47"></a></span>
<span id="cb1-48"><a href="#cb1-48"></a>    Alignment*                                      my_alignment;</span>
<span id="cb1-49"><a href="#cb1-49"></a>    <span class="dt">double</span>*                                         my_birth_rate;</span>
<span id="cb1-50"><a href="#cb1-50"></a>    <span class="dt">double</span>*                                         my_clock_rate;</span>
<span id="cb1-51"><a href="#cb1-51"></a>    RateMatrix_JC*                                  my_rate_matrix;</span>
<span id="cb1-52"><a href="#cb1-52"></a>    Tree*                                           my_tree;</span>
<span id="cb1-53"><a href="#cb1-53"></a></span>
<span id="cb1-54"><a href="#cb1-54"></a>    PureBirthProcess*                               tree_prior;</span>
<span id="cb1-55"><a href="#cb1-55"></a>    ExponentialDistribution*                        birth_rate_prior;</span>
<span id="cb1-56"><a href="#cb1-56"></a>    UniformDistribution*                            clock_rate_prior;</span>
<span id="cb1-57"><a href="#cb1-57"></a>    PhyloCTMC*                                      likelihood;</span>
<span id="cb1-58"><a href="#cb1-58"></a></span>
<span id="cb1-59"><a href="#cb1-59"></a></span>
<span id="cb1-60"><a href="#cb1-60"></a>};</span>
<span id="cb1-61"><a href="#cb1-61"></a></span>
<span id="cb1-62"><a href="#cb1-62"></a><span class="pp">#endif </span><span class="co">/* Model_h */</span></span></code></pre></div>
<h3 id="subsection-7.3.2-implementing-the-model-class">Subsection 7.3.2: Implementing the Model class</h3>
<p>Create a new file called <strong>Model.cpp</strong> Work through the code below which needs to be added to the to file.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1"></a><span class="pp">#include </span><span class="im">&quot;Model.h&quot;</span></span>
<span id="cb2-2"><a href="#cb2-2"></a></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="pp">#include </span><span class="im">&quot;Alignment.h&quot;</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="pp">#include </span><span class="im">&quot;AlignmentReader.h&quot;</span></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="pp">#include </span><span class="im">&quot;ExponentialDistribution.h&quot;</span></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="pp">#include </span><span class="im">&quot;NewickTreeReader.h&quot;</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="pp">#include </span><span class="im">&quot;PhyloCTMC.h&quot;</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="pp">#include </span><span class="im">&quot;PureBirthProcess.h&quot;</span></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="pp">#include </span><span class="im">&quot;RateMatrix_JC.h&quot;</span></span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="pp">#include </span><span class="im">&quot;Tree.h&quot;</span></span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="pp">#include </span><span class="im">&quot;UniformDistribution.h&quot;</span></span>
<span id="cb2-12"><a href="#cb2-12"></a></span>
<span id="cb2-13"><a href="#cb2-13"></a></span>
<span id="cb2-14"><a href="#cb2-14"></a>Model::Model(<span class="at">const</span> <span class="bu">std::</span>string &amp;fn)</span>
<span id="cb2-15"><a href="#cb2-15"></a>{</span>
<span id="cb2-16"><a href="#cb2-16"></a>    <span class="co">// read in some trees</span></span>
<span id="cb2-17"><a href="#cb2-17"></a>    NewickTreeReader tree_reader = NewickTreeReader();</span>
<span id="cb2-18"><a href="#cb2-18"></a>    <span class="bu">std::</span>vector&lt;Tree&gt; trees = tree_reader.readTrees(<span class="st">&quot;primates.tre&quot;</span>);</span>
<span id="cb2-19"><a href="#cb2-19"></a>    Tree* my_tree = <span class="kw">new</span> Tree(trees[<span class="dv">0</span>]);</span>
<span id="cb2-20"><a href="#cb2-20"></a></span>
<span id="cb2-21"><a href="#cb2-21"></a>    <span class="co">// read in the data (i.e., the alignment)</span></span>
<span id="cb2-22"><a href="#cb2-22"></a>    AlignmentReader reader;</span>
<span id="cb2-23"><a href="#cb2-23"></a>    Alignment* my_alignment = <span class="kw">new</span> Alignment( reader.readPhylip( fn ) );</span>
<span id="cb2-24"><a href="#cb2-24"></a></span>
<span id="cb2-25"><a href="#cb2-25"></a></span>
<span id="cb2-26"><a href="#cb2-26"></a>    <span class="co">// create a transition rate matrix</span></span>
<span id="cb2-27"><a href="#cb2-27"></a>    my_rate_matrix = <span class="kw">new</span> RateMatrix_JC();</span>
<span id="cb2-28"><a href="#cb2-28"></a></span>
<span id="cb2-29"><a href="#cb2-29"></a>    <span class="co">// create the clock rate prior</span></span>
<span id="cb2-30"><a href="#cb2-30"></a>    <span class="dt">double</span>* min_clock_rate = <span class="kw">new</span> <span class="dt">double</span>(<span class="fl">0.0</span>);</span>
<span id="cb2-31"><a href="#cb2-31"></a>    <span class="dt">double</span>* max_clock_rate = <span class="kw">new</span> <span class="dt">double</span>(<span class="fl">100.0</span>);</span>
<span id="cb2-32"><a href="#cb2-32"></a>    clock_rate_prior = <span class="kw">new</span> UniformDistribution(min_clock_rate, max_clock_rate);</span>
<span id="cb2-33"><a href="#cb2-33"></a></span>
<span id="cb2-34"><a href="#cb2-34"></a>    my_clock_rate = <span class="kw">new</span> <span class="dt">double</span>(<span class="fl">1.0</span>);</span>
<span id="cb2-35"><a href="#cb2-35"></a>    clock_rate_prior-&gt;setValue( my_clock_rate );</span>
<span id="cb2-36"><a href="#cb2-36"></a></span>
<span id="cb2-37"><a href="#cb2-37"></a>    <span class="co">// now set up the tree prior</span></span>
<span id="cb2-38"><a href="#cb2-38"></a>    <span class="dt">double</span>* birth_rate_mean = <span class="kw">new</span> <span class="dt">double</span>(<span class="fl">1.0</span>);</span>
<span id="cb2-39"><a href="#cb2-39"></a>    birth_rate_prior = <span class="kw">new</span> ExponentialDistribution(birth_rate_mean);</span>
<span id="cb2-40"><a href="#cb2-40"></a></span>
<span id="cb2-41"><a href="#cb2-41"></a>    <span class="co">// specify the birth rate</span></span>
<span id="cb2-42"><a href="#cb2-42"></a>    my_birth_rate = <span class="kw">new</span> <span class="dt">double</span>(<span class="fl">1.0</span>);</span>
<span id="cb2-43"><a href="#cb2-43"></a>    birth_rate_prior-&gt;setValue( my_birth_rate );</span>
<span id="cb2-44"><a href="#cb2-44"></a></span>
<span id="cb2-45"><a href="#cb2-45"></a>    tree_prior = <span class="kw">new</span> PureBirthProcess( my_alignment-&gt;getTaxonNames(), my_birth_rate );</span>
<span id="cb2-46"><a href="#cb2-46"></a>    tree_prior-&gt;setValue( my_tree );</span>
<span id="cb2-47"><a href="#cb2-47"></a></span>
<span id="cb2-48"><a href="#cb2-48"></a>    likelihood = <span class="kw">new</span> PhyloCTMC( my_tree, my_rate_matrix, my_clock_rate );</span>
<span id="cb2-49"><a href="#cb2-49"></a>    likelihood-&gt;setValue( my_alignment );</span>
<span id="cb2-50"><a href="#cb2-50"></a></span>
<span id="cb2-51"><a href="#cb2-51"></a>}</span>
<span id="cb2-52"><a href="#cb2-52"></a></span>
<span id="cb2-53"><a href="#cb2-53"></a>Model::~Model()</span>
<span id="cb2-54"><a href="#cb2-54"></a>{</span>
<span id="cb2-55"><a href="#cb2-55"></a>    <span class="kw">delete</span> my_alignment;</span>
<span id="cb2-56"><a href="#cb2-56"></a>    <span class="kw">delete</span> my_birth_rate;</span>
<span id="cb2-57"><a href="#cb2-57"></a>    <span class="kw">delete</span> my_clock_rate;</span>
<span id="cb2-58"><a href="#cb2-58"></a>    <span class="kw">delete</span> my_rate_matrix;</span>
<span id="cb2-59"><a href="#cb2-59"></a>    <span class="kw">delete</span> my_tree;</span>
<span id="cb2-60"><a href="#cb2-60"></a></span>
<span id="cb2-61"><a href="#cb2-61"></a>    <span class="kw">delete</span> tree_prior;</span>
<span id="cb2-62"><a href="#cb2-62"></a>    <span class="kw">delete</span> birth_rate_prior;</span>
<span id="cb2-63"><a href="#cb2-63"></a>    <span class="kw">delete</span> clock_rate_prior;</span>
<span id="cb2-64"><a href="#cb2-64"></a>    <span class="kw">delete</span> likelihood;</span>
<span id="cb2-65"><a href="#cb2-65"></a>}</span>
<span id="cb2-66"><a href="#cb2-66"></a></span>
<span id="cb2-67"><a href="#cb2-67"></a><span class="dt">double</span> Model::getBirthRate(<span class="dt">void</span>) <span class="at">const</span></span>
<span id="cb2-68"><a href="#cb2-68"></a>{</span>
<span id="cb2-69"><a href="#cb2-69"></a>    <span class="cf">return</span> *my_birth_rate;</span>
<span id="cb2-70"><a href="#cb2-70"></a>}</span>
<span id="cb2-71"><a href="#cb2-71"></a></span>
<span id="cb2-72"><a href="#cb2-72"></a><span class="dt">double</span> Model::getBirthRatePrior(<span class="dt">void</span>)</span>
<span id="cb2-73"><a href="#cb2-73"></a>{</span>
<span id="cb2-74"><a href="#cb2-74"></a>    <span class="cf">return</span> birth_rate_prior-&gt;lnProbability();</span>
<span id="cb2-75"><a href="#cb2-75"></a>}</span>
<span id="cb2-76"><a href="#cb2-76"></a></span>
<span id="cb2-77"><a href="#cb2-77"></a><span class="dt">double</span> Model::getClockRate(<span class="dt">void</span>) <span class="at">const</span></span>
<span id="cb2-78"><a href="#cb2-78"></a>{</span>
<span id="cb2-79"><a href="#cb2-79"></a>     <span class="cf">return</span> *my_clock_rate;</span>
<span id="cb2-80"><a href="#cb2-80"></a>}</span>
<span id="cb2-81"><a href="#cb2-81"></a></span>
<span id="cb2-82"><a href="#cb2-82"></a><span class="dt">double</span> Model::getClockRatePrior(<span class="dt">void</span>)</span>
<span id="cb2-83"><a href="#cb2-83"></a>{</span>
<span id="cb2-84"><a href="#cb2-84"></a>    <span class="cf">return</span> clock_rate_prior-&gt;lnProbability();</span>
<span id="cb2-85"><a href="#cb2-85"></a>}</span>
<span id="cb2-86"><a href="#cb2-86"></a></span>
<span id="cb2-87"><a href="#cb2-87"></a><span class="dt">double</span> Model::getLikelihood(<span class="dt">void</span>)</span>
<span id="cb2-88"><a href="#cb2-88"></a>{</span>
<span id="cb2-89"><a href="#cb2-89"></a>    <span class="cf">return</span> likelihood-&gt;lnProbability();</span>
<span id="cb2-90"><a href="#cb2-90"></a>}</span>
<span id="cb2-91"><a href="#cb2-91"></a></span>
<span id="cb2-92"><a href="#cb2-92"></a><span class="dt">double</span> Model::getTreePrior(<span class="dt">void</span>)</span>
<span id="cb2-93"><a href="#cb2-93"></a>{</span>
<span id="cb2-94"><a href="#cb2-94"></a>    <span class="cf">return</span> tree_prior-&gt;lnProbability();</span>
<span id="cb2-95"><a href="#cb2-95"></a>}</span>
<span id="cb2-96"><a href="#cb2-96"></a></span>
<span id="cb2-97"><a href="#cb2-97"></a><span class="dt">void</span> Model::setBirthRate( <span class="dt">double</span> r )</span>
<span id="cb2-98"><a href="#cb2-98"></a>{</span>
<span id="cb2-99"><a href="#cb2-99"></a>    *my_birth_rate = r;</span>
<span id="cb2-100"><a href="#cb2-100"></a>}</span>
<span id="cb2-101"><a href="#cb2-101"></a><span class="dt">void</span> Model::setClockRate( <span class="dt">double</span> r )</span>
<span id="cb2-102"><a href="#cb2-102"></a>{</span>
<span id="cb2-103"><a href="#cb2-103"></a>    *my_clock_rate = r;</span>
<span id="cb2-104"><a href="#cb2-104"></a>}</span></code></pre></div>
<h3 id="subsection-7.3.3-defining-the-mcmc-class">Subsection 7.3.3: Defining the MCMC class</h3>
<p>Create a new file called <strong>MCMC.h</strong> Work through the code below which needs to be added to the to file.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1"></a><span class="pp">#ifndef MCMC_h</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="pp">#define MCMC_h</span></span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="pp">#include </span><span class="im">&lt;vector&gt;</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="pp">#include </span><span class="im">&lt;string&gt;</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="pp">#include </span><span class="im">&lt;iostream&gt;</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="pp">#include </span><span class="im">&lt;fstream&gt;</span></span>
<span id="cb3-9"><a href="#cb3-9"></a></span>
<span id="cb3-10"><a href="#cb3-10"></a></span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="pp">#include </span><span class="im">&quot;Model.h&quot;</span></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="pp">#include </span><span class="im">&quot;RandomNumberGenerator.h&quot;</span></span>
<span id="cb3-13"><a href="#cb3-13"></a></span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="co">// forward declarations</span></span>
<span id="cb3-15"><a href="#cb3-15"></a></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="co">/**</span></span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="co"> * </span><span class="an">\class</span><span class="co"> </span><span class="cv">MCMC</span></span>
<span id="cb3-18"><a href="#cb3-18"></a><span class="co"> *</span></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="co"> * </span><span class="an">\brief</span><span class="co"> This class represents the MCMC algorithm.</span></span>
<span id="cb3-20"><a href="#cb3-20"></a><span class="co"> *</span></span>
<span id="cb3-21"><a href="#cb3-21"></a><span class="co"> *</span></span>
<span id="cb3-22"><a href="#cb3-22"></a><span class="co"> *</span></span>
<span id="cb3-23"><a href="#cb3-23"></a><span class="co"> * </span><span class="an">\author</span><span class="co"> Sebastian Höhna</span></span>
<span id="cb3-24"><a href="#cb3-24"></a><span class="co"> *</span></span>
<span id="cb3-25"><a href="#cb3-25"></a><span class="co"> */</span></span>
<span id="cb3-26"><a href="#cb3-26"></a><span class="kw">class</span> MCMC {</span>
<span id="cb3-27"><a href="#cb3-27"></a></span>
<span id="cb3-28"><a href="#cb3-28"></a><span class="kw">public</span>:</span>
<span id="cb3-29"><a href="#cb3-29"></a></span>
<span id="cb3-30"><a href="#cb3-30"></a>    MCMC(<span class="at">const</span> <span class="bu">std::</span>string&amp; filename);</span>
<span id="cb3-31"><a href="#cb3-31"></a>    MCMC(<span class="at">const</span> MCMC&amp; m);</span>
<span id="cb3-32"><a href="#cb3-32"></a>    <span class="kw">virtual</span>                                        ~MCMC();</span>
<span id="cb3-33"><a href="#cb3-33"></a></span>
<span id="cb3-34"><a href="#cb3-34"></a>    <span class="dt">void</span>                                            run(<span class="dt">int</span> n_gen);</span>
<span id="cb3-35"><a href="#cb3-35"></a></span>
<span id="cb3-36"><a href="#cb3-36"></a><span class="kw">private</span>:</span>
<span id="cb3-37"><a href="#cb3-37"></a>    <span class="co">// our moves</span></span>
<span id="cb3-38"><a href="#cb3-38"></a>    <span class="dt">void</span>                                            monitorParameters(<span class="dt">int</span> g);</span>
<span id="cb3-39"><a href="#cb3-39"></a>    <span class="dt">void</span>                                            updateBirthRate(<span class="dt">void</span>);</span>
<span id="cb3-40"><a href="#cb3-40"></a>    <span class="dt">void</span>                                            updateClockRate(<span class="dt">void</span>);</span>
<span id="cb3-41"><a href="#cb3-41"></a></span>
<span id="cb3-42"><a href="#cb3-42"></a>    Model                                           my_model;</span>
<span id="cb3-43"><a href="#cb3-43"></a>    RandomNumberGenerator                           rng;</span>
<span id="cb3-44"><a href="#cb3-44"></a>    <span class="bu">std::</span>ofstream                                   parameter_file;</span>
<span id="cb3-45"><a href="#cb3-45"></a>    <span class="bu">std::</span>ofstream                                   tree_file;</span>
<span id="cb3-46"><a href="#cb3-46"></a></span>
<span id="cb3-47"><a href="#cb3-47"></a>};</span>
<span id="cb3-48"><a href="#cb3-48"></a></span>
<span id="cb3-49"><a href="#cb3-49"></a><span class="pp">#endif </span><span class="co">/* MCMC_h */</span></span></code></pre></div>
<h3 id="subsection-7.3.4-implementing-the-mcmc-class">Subsection 7.3.4: Implementing the MCMC class</h3>
<p>Create a new file called <strong>MCMC.cpp</strong> Work through the code below which needs to be added to the to file.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb4-1"><a href="#cb4-1"></a><span class="pp">#include </span><span class="im">&quot;MCMC.h&quot;</span></span>
<span id="cb4-2"><a href="#cb4-2"></a></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="pp">#include </span><span class="im">&lt;math.h&gt;</span><span class="pp">       </span><span class="co">/* isnan, sqrt */</span></span>
<span id="cb4-4"><a href="#cb4-4"></a></span>
<span id="cb4-5"><a href="#cb4-5"></a></span>
<span id="cb4-6"><a href="#cb4-6"></a>MCMC::MCMC( <span class="at">const</span> <span class="bu">std::</span>string &amp;filename ) :</span>
<span id="cb4-7"><a href="#cb4-7"></a>    my_model( filename ),</span>
<span id="cb4-8"><a href="#cb4-8"></a>    parameter_file( <span class="st">&quot;my_analysis.log&quot;</span> ),</span>
<span id="cb4-9"><a href="#cb4-9"></a>    tree_file( <span class="st">&quot;my_analysis.trees&quot;</span> )</span>
<span id="cb4-10"><a href="#cb4-10"></a>{</span>
<span id="cb4-11"><a href="#cb4-11"></a></span>
<span id="cb4-12"><a href="#cb4-12"></a>}</span>
<span id="cb4-13"><a href="#cb4-13"></a></span>
<span id="cb4-14"><a href="#cb4-14"></a>MCMC::MCMC( <span class="at">const</span> MCMC &amp;m ) :</span>
<span id="cb4-15"><a href="#cb4-15"></a>    my_model( <span class="st">&quot;&quot;</span> ),</span>
<span id="cb4-16"><a href="#cb4-16"></a>    parameter_file( <span class="st">&quot;my_analysis.log&quot;</span> ),</span>
<span id="cb4-17"><a href="#cb4-17"></a>    tree_file( <span class="st">&quot;my_analysis.trees&quot;</span> )</span>
<span id="cb4-18"><a href="#cb4-18"></a>{</span>
<span id="cb4-19"><a href="#cb4-19"></a></span>
<span id="cb4-20"><a href="#cb4-20"></a>}</span>
<span id="cb4-21"><a href="#cb4-21"></a></span>
<span id="cb4-22"><a href="#cb4-22"></a></span>
<span id="cb4-23"><a href="#cb4-23"></a>MCMC::~MCMC( <span class="dt">void</span> )</span>
<span id="cb4-24"><a href="#cb4-24"></a>{</span>
<span id="cb4-25"><a href="#cb4-25"></a>    <span class="co">// nothing to do here</span></span>
<span id="cb4-26"><a href="#cb4-26"></a>}</span>
<span id="cb4-27"><a href="#cb4-27"></a></span>
<span id="cb4-28"><a href="#cb4-28"></a></span>
<span id="cb4-29"><a href="#cb4-29"></a></span>
<span id="cb4-30"><a href="#cb4-30"></a><span class="dt">void</span> MCMC::monitorParameters( <span class="dt">int</span> gen )</span>
<span id="cb4-31"><a href="#cb4-31"></a>{</span>
<span id="cb4-32"><a href="#cb4-32"></a>    parameter_file &lt;&lt; gen;</span>
<span id="cb4-33"><a href="#cb4-33"></a>    parameter_file &lt;&lt; <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>;</span>
<span id="cb4-34"><a href="#cb4-34"></a>    parameter_file &lt;&lt; my_model.getBirthRate();</span>
<span id="cb4-35"><a href="#cb4-35"></a>    parameter_file &lt;&lt; <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>;</span>
<span id="cb4-36"><a href="#cb4-36"></a>    parameter_file &lt;&lt; my_model.getClockRate();</span>
<span id="cb4-37"><a href="#cb4-37"></a>    parameter_file &lt;&lt; <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>;</span>
<span id="cb4-38"><a href="#cb4-38"></a>    parameter_file &lt;&lt; <span class="bu">std::</span>endl;</span>
<span id="cb4-39"><a href="#cb4-39"></a>}</span>
<span id="cb4-40"><a href="#cb4-40"></a></span>
<span id="cb4-41"><a href="#cb4-41"></a><span class="dt">void</span> MCMC::updateBirthRate( <span class="dt">void</span> )</span>
<span id="cb4-42"><a href="#cb4-42"></a>{</span>
<span id="cb4-43"><a href="#cb4-43"></a>    <span class="co">// get the current birth rate</span></span>
<span id="cb4-44"><a href="#cb4-44"></a>    <span class="dt">double</span> current_rate = my_model.getBirthRate();</span>
<span id="cb4-45"><a href="#cb4-45"></a></span>
<span id="cb4-46"><a href="#cb4-46"></a>    <span class="co">// draw a new random uniform number</span></span>
<span id="cb4-47"><a href="#cb4-47"></a>    <span class="dt">double</span> u = rng.uniform01();</span>
<span id="cb4-48"><a href="#cb4-48"></a></span>
<span id="cb4-49"><a href="#cb4-49"></a>    <span class="co">// define the window size</span></span>
<span id="cb4-50"><a href="#cb4-50"></a>    <span class="dt">double</span> delta = <span class="fl">7.32</span>;</span>
<span id="cb4-51"><a href="#cb4-51"></a></span>
<span id="cb4-52"><a href="#cb4-52"></a>    <span class="co">// now we compute the new proposed values</span></span>
<span id="cb4-53"><a href="#cb4-53"></a>    <span class="dt">double</span> new_rate = current_rate + (u-<span class="fl">0.5</span>) * delta;</span>
<span id="cb4-54"><a href="#cb4-54"></a></span>
<span id="cb4-55"><a href="#cb4-55"></a>    <span class="co">// compute the prior ratio and likelihood ratio</span></span>
<span id="cb4-56"><a href="#cb4-56"></a>    <span class="dt">double</span> current_prior = my_model.getBirthRatePrior();</span>
<span id="cb4-57"><a href="#cb4-57"></a>    <span class="dt">double</span> current_likelihood = my_model.getTreePrior();</span>
<span id="cb4-58"><a href="#cb4-58"></a></span>
<span id="cb4-59"><a href="#cb4-59"></a>    <span class="co">// set the new value</span></span>
<span id="cb4-60"><a href="#cb4-60"></a>    my_model.setBirthRate( new_rate );</span>
<span id="cb4-61"><a href="#cb4-61"></a></span>
<span id="cb4-62"><a href="#cb4-62"></a>    <span class="dt">double</span> new_prior = my_model.getBirthRatePrior();</span>
<span id="cb4-63"><a href="#cb4-63"></a>    <span class="dt">double</span> new_likelihood = my_model.getTreePrior();</span>
<span id="cb4-64"><a href="#cb4-64"></a></span>
<span id="cb4-65"><a href="#cb4-65"></a>    <span class="dt">double</span> acceptance_prob = new_prior - current_prior + new_likelihood - current_likelihood;</span>
<span id="cb4-66"><a href="#cb4-66"></a></span>
<span id="cb4-67"><a href="#cb4-67"></a>    u = rng.uniform01();</span>
<span id="cb4-68"><a href="#cb4-68"></a></span>
<span id="cb4-69"><a href="#cb4-69"></a>    <span class="cf">if</span> ( isnan(acceptance_prob) || u &gt; acceptance_prob )</span>
<span id="cb4-70"><a href="#cb4-70"></a>    {</span>
<span id="cb4-71"><a href="#cb4-71"></a>        <span class="co">// reject -&gt; reset the value</span></span>
<span id="cb4-72"><a href="#cb4-72"></a>        my_model.setBirthRate( current_rate );</span>
<span id="cb4-73"><a href="#cb4-73"></a>    }</span>
<span id="cb4-74"><a href="#cb4-74"></a>    <span class="cf">else</span></span>
<span id="cb4-75"><a href="#cb4-75"></a>    {</span>
<span id="cb4-76"><a href="#cb4-76"></a>        <span class="co">// accept! nothing to do, because we changed our value already</span></span>
<span id="cb4-77"><a href="#cb4-77"></a>    }</span>
<span id="cb4-78"><a href="#cb4-78"></a></span>
<span id="cb4-79"><a href="#cb4-79"></a></span>
<span id="cb4-80"><a href="#cb4-80"></a>}</span>
<span id="cb4-81"><a href="#cb4-81"></a></span>
<span id="cb4-82"><a href="#cb4-82"></a></span>
<span id="cb4-83"><a href="#cb4-83"></a></span>
<span id="cb4-84"><a href="#cb4-84"></a><span class="dt">void</span> MCMC::updateClockRate( <span class="dt">void</span> )</span>
<span id="cb4-85"><a href="#cb4-85"></a>{</span>
<span id="cb4-86"><a href="#cb4-86"></a>}</span>
<span id="cb4-87"><a href="#cb4-87"></a></span>
<span id="cb4-88"><a href="#cb4-88"></a></span>
<span id="cb4-89"><a href="#cb4-89"></a><span class="dt">void</span> MCMC::run( <span class="dt">int</span> num_generations )</span>
<span id="cb4-90"><a href="#cb4-90"></a>{</span>
<span id="cb4-91"><a href="#cb4-91"></a>    <span class="co">// we assume that the model and all parameters are initialized.</span></span>
<span id="cb4-92"><a href="#cb4-92"></a></span>
<span id="cb4-93"><a href="#cb4-93"></a>    <span class="dt">int</span> thinning = <span class="dv">10</span>;</span>
<span id="cb4-94"><a href="#cb4-94"></a></span>
<span id="cb4-95"><a href="#cb4-95"></a>    <span class="cf">for</span> ( <span class="dt">int</span> current_gen=<span class="dv">0</span>; current_gen&lt;num_generations; current_gen++ )</span>
<span id="cb4-96"><a href="#cb4-96"></a>    {</span>
<span id="cb4-97"><a href="#cb4-97"></a>        <span class="co">// draw new values:</span></span>
<span id="cb4-98"><a href="#cb4-98"></a>        updateBirthRate();</span>
<span id="cb4-99"><a href="#cb4-99"></a></span>
<span id="cb4-100"><a href="#cb4-100"></a>        updateClockRate();</span>
<span id="cb4-101"><a href="#cb4-101"></a></span>
<span id="cb4-102"><a href="#cb4-102"></a>        <span class="co">// now we monitor the variables</span></span>
<span id="cb4-103"><a href="#cb4-103"></a>        <span class="cf">if</span> ( current_gen % thinning == <span class="dv">0</span> )</span>
<span id="cb4-104"><a href="#cb4-104"></a>        {</span>
<span id="cb4-105"><a href="#cb4-105"></a>            monitorParameters( current_gen );</span>
<span id="cb4-106"><a href="#cb4-106"></a>        }</span>
<span id="cb4-107"><a href="#cb4-107"></a></span>
<span id="cb4-108"><a href="#cb4-108"></a>    }</span>
<span id="cb4-109"><a href="#cb4-109"></a></span>
<span id="cb4-110"><a href="#cb4-110"></a>    <span class="bu">std::</span>cout &lt;&lt; <span class="st">&quot;Hooray, we finished our MCMC run!&quot;</span> &lt;&lt; <span class="bu">std::</span>endl;</span>
<span id="cb4-111"><a href="#cb4-111"></a>}</span></code></pre></div>
<h2 id="section-7.4-exercises">Section 7.4: Exercises</h2>
<ul>
<li>Implement the method <strong>updateClockRate</strong> using the same logic as we used for <strong>updateBirthRate</strong>.</li>
<li>Experiment with the window size parameter, which we arbitrarily set to 7.32. That is, run the MCMC with different values for the window size and look at the results in the software <em>Tracer</em> by loading the file called <em>my_analysis.log</em>.</li>
<li>In our MCMC, we implement a sliding window move. Now let’s implement a scaling move. To do so, you will propose new values by <span class="math inline">\(\theta&#39; = \theta * e^{u-0.5}\)</span>, where <span class="math inline">\(u \sim \text{unif}(0,1)\)</span>. Note that you will also need to compute the <em>Hastings ratio</em>, which is <span class="math inline">\(e^{u-0.5}\)</span> (or <span class="math inline">\(u-0.5\)</span> since we need to add the log-transformed Hastings ratio).</li>
<li>Compare which MCMC works best (e.g., using only the sliding window move, only the scaling move, or both moves combined). Also check if the samples generated from MCMC runs using the different moves give (approximately) the same posterior distribution.</li>
</ul>
<div>
<h2 id="references">References</h2>
</div>
</body>
</html>
